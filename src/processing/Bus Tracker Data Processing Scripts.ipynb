{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import arrow\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [Introduction](#introduction)\n",
    "* [To Do](#todo)\n",
    "* [Loading Raw Vehicle Position Data](#loading)\n",
    "* [Downloading and Parsing Patterns](#patterns)\n",
    "* [Cleaning the raw data](#cleaning)\n",
    "* [Building timetables](#timetable)\n",
    "* [Derived Data](#derived)\n",
    "    * [Trip and Wait Times](#trips_waits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "This notebook contains the scripts used to clean and transform bus position data collected from the **`getvehicles`** API. The data processing is conducted as follows:\n",
    "1. Load the raw vehicle position data into a pandas DataFrame. Filter out any undesired bus routes.\n",
    "2. Download bus route patterns from the **`getpatterns`** API.\n",
    "3. Load route patterns into a pandas DataFrame.\n",
    "4. Clean the raw vehicle position data, including removing duplicate rows, and assigning each bus trip a unique ID.\n",
    "5. For each bus route, transform the raw vehicle data into a timetable DataFrame, with bus stops as the columns and individual trips as rows.\n",
    "6. Using each bus route's timetable DataFrame, calculate the travel times between each bus stop and the wait times between adjacent buses at each stop, and store in a new DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do <a name=\"todo\"></a>\n",
    "* Breakup Jupyter notebook into standalone Python scripts for data processing\n",
    "* Flag bad vehicle position data? e.g. Check monotonicity, count number of data points.\n",
    "* Write functions to keep track of access date when downloading patterns from the **`getpatterns`** API, and create new file if pattern has changed\n",
    "* Load raw pattern data in a more elegant and simpler way. Current loading process is a holdover from a different way of processing patterns data.\n",
    "* Edit code for consistent style.\n",
    "* Completed detailed function descriptions and useage notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Raw Vehicle Position Data <a name=\"loading\"></a>\n",
    "\n",
    "`load_raw_data`  \n",
    "Loads raw vehicle position data from possibly multiple file sources into one DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_raw_data(path, file_stem):\n",
    "    names = ['tripid', 'tmstmp', 'pid', 'rt', 'pdist', 'dly']\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path, \"*{}.csv\".format(file_stem)))\n",
    "    df_each = (pd.read_csv(f, skiprows=1, names=names, dtype=str) for f in all_files)\n",
    "    df = pd.concat(df_each, ignore_index=True)\n",
    "    \n",
    "    df.dropna(how='any', inplace=True)\n",
    "    df.tmstmp =  pd.to_datetime(df.tmstmp)\n",
    "    df.pdist = df.pdist.astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "\n",
    "def load_raw_data2(db_path, rt, start, end):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        df = pd.read_sql_query(\"SELECT * FROM vehicles WHERE rt=?\", conn, params=(rt,))\n",
    "        df = pd.read_sql_query(\"SELECT * FROM vehicles WHERE rt=? AND tmstmp BETWEEN ? AND ?;\", conn, params=(rt,start,end,))\n",
    "        df = pd.read_sql_query(\"SELECT * FROM vehicles WHERE rt=? AND tmstmp >= ?;\", conn, params=(rt,start,))\n",
    "        df = pd.read_sql_query(\"SELECT * FROM vehicles WHERE rt=? AND tmstmp <= ?;\", conn, params=(rt,end,))        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = load_raw_data2(\"../../test.db\", \"66\", \"20190116 12:00:00\", \"20190116 17:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "      <th>tmstmp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>hdg</th>\n",
       "      <th>pid</th>\n",
       "      <th>rt</th>\n",
       "      <th>des</th>\n",
       "      <th>pdist</th>\n",
       "      <th>dly</th>\n",
       "      <th>tatripid</th>\n",
       "      <th>tablockid</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:00:27</td>\n",
       "      <td>41.9036710858345</td>\n",
       "      <td>-87.64569437503815</td>\n",
       "      <td>268</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>17472</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:00:25</td>\n",
       "      <td>41.8956553331062</td>\n",
       "      <td>-87.69416695210471</td>\n",
       "      <td>88</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>8901</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:00:32</td>\n",
       "      <td>41.886938872160734</td>\n",
       "      <td>-87.62462399329668</td>\n",
       "      <td>177</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>39680</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:01:04</td>\n",
       "      <td>41.90230736365685</td>\n",
       "      <td>-87.64806600717398</td>\n",
       "      <td>177</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>18608</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:01:21</td>\n",
       "      <td>41.895751953125</td>\n",
       "      <td>-87.68759862726385</td>\n",
       "      <td>93</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>10713</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:01:03</td>\n",
       "      <td>41.88548253377279</td>\n",
       "      <td>-87.62452748616536</td>\n",
       "      <td>177</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>40212</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:02:29</td>\n",
       "      <td>41.896397181919646</td>\n",
       "      <td>-87.64796120779855</td>\n",
       "      <td>269</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>20767</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:02:27</td>\n",
       "      <td>41.89575746324327</td>\n",
       "      <td>-87.68458585385923</td>\n",
       "      <td>89</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>11534</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:02:22</td>\n",
       "      <td>41.88317165374756</td>\n",
       "      <td>-87.62446479797363</td>\n",
       "      <td>176</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>41039</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:03:26</td>\n",
       "      <td>41.896358489990234</td>\n",
       "      <td>-87.6537615868353</td>\n",
       "      <td>269</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>22426</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:03:22</td>\n",
       "      <td>41.895870208740234</td>\n",
       "      <td>-87.67997309846699</td>\n",
       "      <td>89</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>12801</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:03:04</td>\n",
       "      <td>41.882112979888916</td>\n",
       "      <td>-87.62716770172119</td>\n",
       "      <td>5</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42133</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:04:28</td>\n",
       "      <td>41.89630401134491</td>\n",
       "      <td>-87.65747511386871</td>\n",
       "      <td>268</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>23459</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:04:05</td>\n",
       "      <td>41.895912170410156</td>\n",
       "      <td>-87.67778805324009</td>\n",
       "      <td>90</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>13394</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:04:05</td>\n",
       "      <td>41.882110595703125</td>\n",
       "      <td>-87.62734527587891</td>\n",
       "      <td>1</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42181</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:05:32</td>\n",
       "      <td>41.896183013916016</td>\n",
       "      <td>-87.6642338145863</td>\n",
       "      <td>268</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>25302</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:05:32</td>\n",
       "      <td>41.89599459099047</td>\n",
       "      <td>-87.67175662878788</td>\n",
       "      <td>88</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>15032</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:05:06</td>\n",
       "      <td>41.882110595703125</td>\n",
       "      <td>-87.62734527587891</td>\n",
       "      <td>1</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42181</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:06:28</td>\n",
       "      <td>41.89646478909165</td>\n",
       "      <td>-87.67038453514897</td>\n",
       "      <td>271</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>26990</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:06:07</td>\n",
       "      <td>41.89603266996496</td>\n",
       "      <td>-87.66788011438706</td>\n",
       "      <td>90</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>16102</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:06:07</td>\n",
       "      <td>41.882110595703125</td>\n",
       "      <td>-87.62734527587891</td>\n",
       "      <td>1</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42181</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:07:23</td>\n",
       "      <td>41.89602764069088</td>\n",
       "      <td>-87.67455400739398</td>\n",
       "      <td>271</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>28372</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:07:11</td>\n",
       "      <td>41.8960953914758</td>\n",
       "      <td>-87.66729377977776</td>\n",
       "      <td>85</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>16274</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:07:09</td>\n",
       "      <td>41.882110595703125</td>\n",
       "      <td>-87.62734527587891</td>\n",
       "      <td>1</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42181</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:08:31</td>\n",
       "      <td>41.895907447451634</td>\n",
       "      <td>-87.6816173735119</td>\n",
       "      <td>268</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>30241</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:08:26</td>\n",
       "      <td>41.896141052246094</td>\n",
       "      <td>-87.6619873046875</td>\n",
       "      <td>90</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>17739</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:08:10</td>\n",
       "      <td>41.882110595703125</td>\n",
       "      <td>-87.62734527587891</td>\n",
       "      <td>1</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42181</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 03:09:28</td>\n",
       "      <td>41.89581518906813</td>\n",
       "      <td>-87.6867011143611</td>\n",
       "      <td>269</td>\n",
       "      <td>4344</td>\n",
       "      <td>66</td>\n",
       "      <td>Pulaski</td>\n",
       "      <td>31650</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 03:09:27</td>\n",
       "      <td>41.896141052246094</td>\n",
       "      <td>-87.6619873046875</td>\n",
       "      <td>90</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>17739</td>\n",
       "      <td>0</td>\n",
       "      <td>835</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 03:09:11</td>\n",
       "      <td>41.882110595703125</td>\n",
       "      <td>-87.62734527587891</td>\n",
       "      <td>1</td>\n",
       "      <td>4353</td>\n",
       "      <td>66</td>\n",
       "      <td>Washington/State</td>\n",
       "      <td>42181</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>SN  -801</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14928</th>\n",
       "      <td>1986</td>\n",
       "      <td>20190116 16:59:28</td>\n",
       "      <td>41.894927978515625</td>\n",
       "      <td>-87.74892089326502</td>\n",
       "      <td>89</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>7037</td>\n",
       "      <td>0</td>\n",
       "      <td>10005606</td>\n",
       "      <td>66 -809</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14929</th>\n",
       "      <td>1832</td>\n",
       "      <td>20190116 16:59:31</td>\n",
       "      <td>41.895206451416016</td>\n",
       "      <td>-87.72471405029297</td>\n",
       "      <td>84</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>13661</td>\n",
       "      <td>0</td>\n",
       "      <td>10005598</td>\n",
       "      <td>66 -853</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14930</th>\n",
       "      <td>1984</td>\n",
       "      <td>20190116 16:59:19</td>\n",
       "      <td>41.89539601252629</td>\n",
       "      <td>-87.72079702524039</td>\n",
       "      <td>82</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>14784</td>\n",
       "      <td>0</td>\n",
       "      <td>10005597</td>\n",
       "      <td>66 -807</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14931</th>\n",
       "      <td>8147</td>\n",
       "      <td>20190116 16:59:16</td>\n",
       "      <td>41.89570304995677</td>\n",
       "      <td>-87.68679159195696</td>\n",
       "      <td>89</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>24135</td>\n",
       "      <td>0</td>\n",
       "      <td>10005590</td>\n",
       "      <td>66 -806</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14932</th>\n",
       "      <td>2023</td>\n",
       "      <td>20190116 16:59:25</td>\n",
       "      <td>41.89588928222656</td>\n",
       "      <td>-87.67721557617188</td>\n",
       "      <td>92</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>26691</td>\n",
       "      <td>0</td>\n",
       "      <td>10005596</td>\n",
       "      <td>SN  -855</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14933</th>\n",
       "      <td>8192</td>\n",
       "      <td>20190116 16:59:11</td>\n",
       "      <td>41.896146600896664</td>\n",
       "      <td>-87.66188465465198</td>\n",
       "      <td>90</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>30958</td>\n",
       "      <td>0</td>\n",
       "      <td>10005589</td>\n",
       "      <td>N66 -892</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14934</th>\n",
       "      <td>1394</td>\n",
       "      <td>20190116 16:59:19</td>\n",
       "      <td>41.89631652832031</td>\n",
       "      <td>-87.65410614013672</td>\n",
       "      <td>88</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>33047</td>\n",
       "      <td>0</td>\n",
       "      <td>10005588</td>\n",
       "      <td>66 -852</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>8115</td>\n",
       "      <td>20190116 16:59:28</td>\n",
       "      <td>41.89645614624023</td>\n",
       "      <td>-87.63998107910156</td>\n",
       "      <td>88</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>41926</td>\n",
       "      <td>0</td>\n",
       "      <td>10005587</td>\n",
       "      <td>SN  -854</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>1390</td>\n",
       "      <td>20190116 16:59:30</td>\n",
       "      <td>41.89667854309082</td>\n",
       "      <td>-87.62628860473633</td>\n",
       "      <td>86</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>45640</td>\n",
       "      <td>0</td>\n",
       "      <td>10005586</td>\n",
       "      <td>66 -808</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>1967</td>\n",
       "      <td>20190116 16:59:19</td>\n",
       "      <td>41.89674377441406</td>\n",
       "      <td>-87.62108631134033</td>\n",
       "      <td>89</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>47051</td>\n",
       "      <td>0</td>\n",
       "      <td>10005580</td>\n",
       "      <td>66 -805</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>1978</td>\n",
       "      <td>20190116 16:59:20</td>\n",
       "      <td>41.8937313079834</td>\n",
       "      <td>-87.62033081054688</td>\n",
       "      <td>183</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>48303</td>\n",
       "      <td>0</td>\n",
       "      <td>10005579</td>\n",
       "      <td>66 -804</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>8150</td>\n",
       "      <td>20190116 16:59:08</td>\n",
       "      <td>41.89288520812988</td>\n",
       "      <td>-87.61016845703125</td>\n",
       "      <td>128</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>52605</td>\n",
       "      <td>0</td>\n",
       "      <td>10005577</td>\n",
       "      <td>SN  -852</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14940</th>\n",
       "      <td>1981</td>\n",
       "      <td>20190116 16:59:22</td>\n",
       "      <td>41.89284242902483</td>\n",
       "      <td>-87.61015792120071</td>\n",
       "      <td>178</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>52621</td>\n",
       "      <td>0</td>\n",
       "      <td>10005578</td>\n",
       "      <td>66 -821</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14941</th>\n",
       "      <td>1968</td>\n",
       "      <td>20190116 16:59:31</td>\n",
       "      <td>41.892024993896484</td>\n",
       "      <td>-87.61148071289062</td>\n",
       "      <td>263</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>10005620</td>\n",
       "      <td>66 -867</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14942</th>\n",
       "      <td>2009</td>\n",
       "      <td>20190116 16:59:13</td>\n",
       "      <td>41.89180434959522</td>\n",
       "      <td>-87.61974898628567</td>\n",
       "      <td>264</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>2843</td>\n",
       "      <td>0</td>\n",
       "      <td>10005619</td>\n",
       "      <td>66 -866</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14943</th>\n",
       "      <td>2004</td>\n",
       "      <td>20190116 16:59:25</td>\n",
       "      <td>41.896827697753906</td>\n",
       "      <td>-87.6214782169887</td>\n",
       "      <td>264</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>4998</td>\n",
       "      <td>0</td>\n",
       "      <td>10005611</td>\n",
       "      <td>66 -865</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14944</th>\n",
       "      <td>8197</td>\n",
       "      <td>20190116 16:59:18</td>\n",
       "      <td>41.89673547744751</td>\n",
       "      <td>-87.62789535522461</td>\n",
       "      <td>271</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>6741</td>\n",
       "      <td>0</td>\n",
       "      <td>10005614</td>\n",
       "      <td>N66 -894</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14945</th>\n",
       "      <td>1935</td>\n",
       "      <td>20190116 16:59:27</td>\n",
       "      <td>41.89665813446045</td>\n",
       "      <td>-87.63575744628906</td>\n",
       "      <td>262</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>8876</td>\n",
       "      <td>0</td>\n",
       "      <td>10005613</td>\n",
       "      <td>66 -818</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14946</th>\n",
       "      <td>1381</td>\n",
       "      <td>20190116 16:59:22</td>\n",
       "      <td>41.90365332144278</td>\n",
       "      <td>-87.64695965802228</td>\n",
       "      <td>265</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>14588</td>\n",
       "      <td>0</td>\n",
       "      <td>10005612</td>\n",
       "      <td>66 -859</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14947</th>\n",
       "      <td>8141</td>\n",
       "      <td>20190116 16:59:02</td>\n",
       "      <td>41.896236419677734</td>\n",
       "      <td>-87.6624116897583</td>\n",
       "      <td>268</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>21587</td>\n",
       "      <td>0</td>\n",
       "      <td>10005633</td>\n",
       "      <td>66 -860</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14948</th>\n",
       "      <td>1999</td>\n",
       "      <td>20190116 16:59:16</td>\n",
       "      <td>41.89618606567383</td>\n",
       "      <td>-87.6649658203125</td>\n",
       "      <td>268</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>22284</td>\n",
       "      <td>0</td>\n",
       "      <td>10005603</td>\n",
       "      <td>66 -816</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14949</th>\n",
       "      <td>8180</td>\n",
       "      <td>20190116 16:59:23</td>\n",
       "      <td>41.895545959472656</td>\n",
       "      <td>-87.7163744839755</td>\n",
       "      <td>271</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>36378</td>\n",
       "      <td>0</td>\n",
       "      <td>10005601</td>\n",
       "      <td>66 -857</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14950</th>\n",
       "      <td>8156</td>\n",
       "      <td>20190116 16:59:18</td>\n",
       "      <td>41.895486195882164</td>\n",
       "      <td>-87.7193261605722</td>\n",
       "      <td>272</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>37196</td>\n",
       "      <td>0</td>\n",
       "      <td>10005629</td>\n",
       "      <td>SN  -859</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14951</th>\n",
       "      <td>1966</td>\n",
       "      <td>20190116 16:59:27</td>\n",
       "      <td>41.895466804504395</td>\n",
       "      <td>-87.72170352935791</td>\n",
       "      <td>269</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>37846</td>\n",
       "      <td>0</td>\n",
       "      <td>10005615</td>\n",
       "      <td>SN  -851</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952</th>\n",
       "      <td>8100</td>\n",
       "      <td>20190116 16:59:16</td>\n",
       "      <td>41.895059179087156</td>\n",
       "      <td>-87.7475211972096</td>\n",
       "      <td>273</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>44985</td>\n",
       "      <td>0</td>\n",
       "      <td>10005592</td>\n",
       "      <td>66 -854</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14953</th>\n",
       "      <td>8120</td>\n",
       "      <td>20190116 16:59:14</td>\n",
       "      <td>41.89503338462428</td>\n",
       "      <td>-87.75314090126439</td>\n",
       "      <td>269</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>46461</td>\n",
       "      <td>0</td>\n",
       "      <td>10005593</td>\n",
       "      <td>SN  -858</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14954</th>\n",
       "      <td>8101</td>\n",
       "      <td>20190116 16:59:31</td>\n",
       "      <td>41.89519200559522</td>\n",
       "      <td>-87.77473349649398</td>\n",
       "      <td>140</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>52601</td>\n",
       "      <td>1</td>\n",
       "      <td>10005584</td>\n",
       "      <td>66 -810</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14955</th>\n",
       "      <td>8145</td>\n",
       "      <td>20190116 16:59:18</td>\n",
       "      <td>41.897884368896484</td>\n",
       "      <td>-87.70663452148438</td>\n",
       "      <td>118</td>\n",
       "      <td>8183</td>\n",
       "      <td>66</td>\n",
       "      <td>Grand</td>\n",
       "      <td>34275</td>\n",
       "      <td>0</td>\n",
       "      <td>10005594</td>\n",
       "      <td>N66 -893</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14956</th>\n",
       "      <td>1981</td>\n",
       "      <td>20190116 16:59:52</td>\n",
       "      <td>41.89284242902483</td>\n",
       "      <td>-87.61015792120071</td>\n",
       "      <td>178</td>\n",
       "      <td>6662</td>\n",
       "      <td>66</td>\n",
       "      <td>Navy Pier</td>\n",
       "      <td>52621</td>\n",
       "      <td>0</td>\n",
       "      <td>10005578</td>\n",
       "      <td>66 -821</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14957</th>\n",
       "      <td>1381</td>\n",
       "      <td>20190116 16:59:52</td>\n",
       "      <td>41.90365226180465</td>\n",
       "      <td>-87.647014759205</td>\n",
       "      <td>265</td>\n",
       "      <td>6665</td>\n",
       "      <td>66</td>\n",
       "      <td>Austin</td>\n",
       "      <td>14603</td>\n",
       "      <td>0</td>\n",
       "      <td>10005612</td>\n",
       "      <td>66 -859</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14958 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        vid             tmstmp                 lat                 lon  hdg  \\\n",
       "0      8197  20190116 03:00:27    41.9036710858345  -87.64569437503815  268   \n",
       "1      8192  20190116 03:00:25    41.8956553331062  -87.69416695210471   88   \n",
       "2      8150  20190116 03:00:32  41.886938872160734  -87.62462399329668  177   \n",
       "3      8197  20190116 03:01:04   41.90230736365685  -87.64806600717398  177   \n",
       "4      8192  20190116 03:01:21     41.895751953125  -87.68759862726385   93   \n",
       "5      8150  20190116 03:01:03   41.88548253377279  -87.62452748616536  177   \n",
       "6      8197  20190116 03:02:29  41.896397181919646  -87.64796120779855  269   \n",
       "7      8192  20190116 03:02:27   41.89575746324327  -87.68458585385923   89   \n",
       "8      8150  20190116 03:02:22   41.88317165374756  -87.62446479797363  176   \n",
       "9      8197  20190116 03:03:26  41.896358489990234   -87.6537615868353  269   \n",
       "10     8192  20190116 03:03:22  41.895870208740234  -87.67997309846699   89   \n",
       "11     8150  20190116 03:03:04  41.882112979888916  -87.62716770172119    5   \n",
       "12     8197  20190116 03:04:28   41.89630401134491  -87.65747511386871  268   \n",
       "13     8192  20190116 03:04:05  41.895912170410156  -87.67778805324009   90   \n",
       "14     8150  20190116 03:04:05  41.882110595703125  -87.62734527587891    1   \n",
       "15     8197  20190116 03:05:32  41.896183013916016   -87.6642338145863  268   \n",
       "16     8192  20190116 03:05:32   41.89599459099047  -87.67175662878788   88   \n",
       "17     8150  20190116 03:05:06  41.882110595703125  -87.62734527587891    1   \n",
       "18     8197  20190116 03:06:28   41.89646478909165  -87.67038453514897  271   \n",
       "19     8192  20190116 03:06:07   41.89603266996496  -87.66788011438706   90   \n",
       "20     8150  20190116 03:06:07  41.882110595703125  -87.62734527587891    1   \n",
       "21     8197  20190116 03:07:23   41.89602764069088  -87.67455400739398  271   \n",
       "22     8192  20190116 03:07:11    41.8960953914758  -87.66729377977776   85   \n",
       "23     8150  20190116 03:07:09  41.882110595703125  -87.62734527587891    1   \n",
       "24     8197  20190116 03:08:31  41.895907447451634   -87.6816173735119  268   \n",
       "25     8192  20190116 03:08:26  41.896141052246094   -87.6619873046875   90   \n",
       "26     8150  20190116 03:08:10  41.882110595703125  -87.62734527587891    1   \n",
       "27     8197  20190116 03:09:28   41.89581518906813   -87.6867011143611  269   \n",
       "28     8192  20190116 03:09:27  41.896141052246094   -87.6619873046875   90   \n",
       "29     8150  20190116 03:09:11  41.882110595703125  -87.62734527587891    1   \n",
       "...     ...                ...                 ...                 ...  ...   \n",
       "14928  1986  20190116 16:59:28  41.894927978515625  -87.74892089326502   89   \n",
       "14929  1832  20190116 16:59:31  41.895206451416016  -87.72471405029297   84   \n",
       "14930  1984  20190116 16:59:19   41.89539601252629  -87.72079702524039   82   \n",
       "14931  8147  20190116 16:59:16   41.89570304995677  -87.68679159195696   89   \n",
       "14932  2023  20190116 16:59:25   41.89588928222656  -87.67721557617188   92   \n",
       "14933  8192  20190116 16:59:11  41.896146600896664  -87.66188465465198   90   \n",
       "14934  1394  20190116 16:59:19   41.89631652832031  -87.65410614013672   88   \n",
       "14935  8115  20190116 16:59:28   41.89645614624023  -87.63998107910156   88   \n",
       "14936  1390  20190116 16:59:30   41.89667854309082  -87.62628860473633   86   \n",
       "14937  1967  20190116 16:59:19   41.89674377441406  -87.62108631134033   89   \n",
       "14938  1978  20190116 16:59:20    41.8937313079834  -87.62033081054688  183   \n",
       "14939  8150  20190116 16:59:08   41.89288520812988  -87.61016845703125  128   \n",
       "14940  1981  20190116 16:59:22   41.89284242902483  -87.61015792120071  178   \n",
       "14941  1968  20190116 16:59:31  41.892024993896484  -87.61148071289062  263   \n",
       "14942  2009  20190116 16:59:13   41.89180434959522  -87.61974898628567  264   \n",
       "14943  2004  20190116 16:59:25  41.896827697753906   -87.6214782169887  264   \n",
       "14944  8197  20190116 16:59:18   41.89673547744751  -87.62789535522461  271   \n",
       "14945  1935  20190116 16:59:27   41.89665813446045  -87.63575744628906  262   \n",
       "14946  1381  20190116 16:59:22   41.90365332144278  -87.64695965802228  265   \n",
       "14947  8141  20190116 16:59:02  41.896236419677734   -87.6624116897583  268   \n",
       "14948  1999  20190116 16:59:16   41.89618606567383   -87.6649658203125  268   \n",
       "14949  8180  20190116 16:59:23  41.895545959472656   -87.7163744839755  271   \n",
       "14950  8156  20190116 16:59:18  41.895486195882164   -87.7193261605722  272   \n",
       "14951  1966  20190116 16:59:27  41.895466804504395  -87.72170352935791  269   \n",
       "14952  8100  20190116 16:59:16  41.895059179087156   -87.7475211972096  273   \n",
       "14953  8120  20190116 16:59:14   41.89503338462428  -87.75314090126439  269   \n",
       "14954  8101  20190116 16:59:31   41.89519200559522  -87.77473349649398  140   \n",
       "14955  8145  20190116 16:59:18  41.897884368896484  -87.70663452148438  118   \n",
       "14956  1981  20190116 16:59:52   41.89284242902483  -87.61015792120071  178   \n",
       "14957  1381  20190116 16:59:52   41.90365226180465    -87.647014759205  265   \n",
       "\n",
       "        pid  rt               des  pdist dly  tatripid tablockid zone  \n",
       "0      4344  66           Pulaski  17472   0       839  N66 -894       \n",
       "1      4353  66  Washington/State   8901   0       835  N66 -892       \n",
       "2      4353  66  Washington/State  39680   0       834  SN  -801       \n",
       "3      4344  66           Pulaski  18608   0       839  N66 -894       \n",
       "4      4353  66  Washington/State  10713   0       835  N66 -892       \n",
       "5      4353  66  Washington/State  40212   0       834  SN  -801       \n",
       "6      4344  66           Pulaski  20767   0       839  N66 -894       \n",
       "7      4353  66  Washington/State  11534   0       835  N66 -892       \n",
       "8      4353  66  Washington/State  41039   0       834  SN  -801       \n",
       "9      4344  66           Pulaski  22426   0       839  N66 -894       \n",
       "10     4353  66  Washington/State  12801   0       835  N66 -892       \n",
       "11     4353  66  Washington/State  42133   0       834  SN  -801       \n",
       "12     4344  66           Pulaski  23459   0       839  N66 -894       \n",
       "13     4353  66  Washington/State  13394   0       835  N66 -892       \n",
       "14     4353  66  Washington/State  42181   0       834  SN  -801       \n",
       "15     4344  66           Pulaski  25302   0       839  N66 -894       \n",
       "16     4353  66  Washington/State  15032   0       835  N66 -892       \n",
       "17     4353  66  Washington/State  42181   0       834  SN  -801       \n",
       "18     4344  66           Pulaski  26990   0       839  N66 -894       \n",
       "19     4353  66  Washington/State  16102   0       835  N66 -892       \n",
       "20     4353  66  Washington/State  42181   0       834  SN  -801       \n",
       "21     4344  66           Pulaski  28372   0       839  N66 -894       \n",
       "22     4353  66  Washington/State  16274   0       835  N66 -892       \n",
       "23     4353  66  Washington/State  42181   0       834  SN  -801       \n",
       "24     4344  66           Pulaski  30241   0       839  N66 -894       \n",
       "25     4353  66  Washington/State  17739   0       835  N66 -892       \n",
       "26     4353  66  Washington/State  42181   0       834  SN  -801       \n",
       "27     4344  66           Pulaski  31650   0       839  N66 -894       \n",
       "28     4353  66  Washington/State  17739   0       835  N66 -892       \n",
       "29     4353  66  Washington/State  42181   0       834  SN  -801       \n",
       "...     ...  ..               ...    ...  ..       ...       ...  ...  \n",
       "14928  6662  66         Navy Pier   7037   0  10005606   66 -809       \n",
       "14929  6662  66         Navy Pier  13661   0  10005598   66 -853       \n",
       "14930  6662  66         Navy Pier  14784   0  10005597   66 -807       \n",
       "14931  6662  66         Navy Pier  24135   0  10005590   66 -806       \n",
       "14932  6662  66         Navy Pier  26691   0  10005596  SN  -855       \n",
       "14933  6662  66         Navy Pier  30958   0  10005589  N66 -892       \n",
       "14934  6662  66         Navy Pier  33047   0  10005588   66 -852       \n",
       "14935  6662  66         Navy Pier  41926   0  10005587  SN  -854       \n",
       "14936  6662  66         Navy Pier  45640   0  10005586   66 -808       \n",
       "14937  6662  66         Navy Pier  47051   0  10005580   66 -805       \n",
       "14938  6662  66         Navy Pier  48303   0  10005579   66 -804       \n",
       "14939  6662  66         Navy Pier  52605   0  10005577  SN  -852       \n",
       "14940  6662  66         Navy Pier  52621   0  10005578   66 -821       \n",
       "14941  6665  66            Austin    483   0  10005620   66 -867       \n",
       "14942  6665  66            Austin   2843   0  10005619   66 -866       \n",
       "14943  6665  66            Austin   4998   0  10005611   66 -865       \n",
       "14944  6665  66            Austin   6741   0  10005614  N66 -894       \n",
       "14945  6665  66            Austin   8876   0  10005613   66 -818       \n",
       "14946  6665  66            Austin  14588   0  10005612   66 -859       \n",
       "14947  6665  66            Austin  21587   0  10005633   66 -860       \n",
       "14948  6665  66            Austin  22284   0  10005603   66 -816       \n",
       "14949  6665  66            Austin  36378   0  10005601   66 -857       \n",
       "14950  6665  66            Austin  37196   0  10005629  SN  -859       \n",
       "14951  6665  66            Austin  37846   0  10005615  SN  -851       \n",
       "14952  6665  66            Austin  44985   0  10005592   66 -854       \n",
       "14953  6665  66            Austin  46461   0  10005593  SN  -858       \n",
       "14954  6665  66            Austin  52601   1  10005584   66 -810       \n",
       "14955  8183  66             Grand  34275   0  10005594  N66 -893       \n",
       "14956  6662  66         Navy Pier  52621   0  10005578   66 -821       \n",
       "14957  6665  66            Austin  14603   0  10005612   66 -859       \n",
       "\n",
       "[14958 rows x 13 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Parsing Patterns <a name=\"patterns\"></a>\n",
    "\n",
    "`check_if_path_exists`  \n",
    "Checks if the given directories exists. If they do not exist, it creates them.\n",
    "\n",
    "`get_patterns`  \n",
    "Queries the **`getpatterns`** API to obtain information patterns present in given DataFrame. Each pattern is written to a separate .json file of the form *RouteNumber_PatternID.json*.\n",
    "\n",
    "Note: It is not possible to use the **`getpatterns`** API to access all patterns associated with a particular bus route. One either has the option to request all *active* patterns for a particular bus route or to request patterns individually by their pattern ID. This script does the latter.\n",
    "\n",
    "`untangle_pattern_columns` and `pattern_dict_to_df` are supporting functions for `load_patterns`.\n",
    "\n",
    "`load_patterns`\n",
    "Loads the patterns for a particular bus route into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ConfigParser.ConfigParser()\n",
    "config.read(\"../../keys.config\")\n",
    "API_KEY = config.get(\"ctabustracker\", \"api_key\")\n",
    "URL = \"http://www.ctabustracker.com/bustime/api/v2/getpatterns\"\n",
    "patterns_path = \"../../data/raw/getpatterns/\"\n",
    "\n",
    "def check_if_path_exists(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "def get_patterns(df):\n",
    "    check_if_path_exists(patterns_path)\n",
    "    \n",
    "    pids = [str(pid) for pid in df.pid.unique()]\n",
    "    # the getpatterns API only accepts upto 10 patterns at a time\n",
    "    pids_chunks = [pids[i:i+10] for i in xrange(0, len(pids), 10)]\n",
    "    for chunk in pids_chunks:\n",
    "        pids_str = \",\".join(chunk)\n",
    "        payload = {'key': API_KEY, 'pid': pids_str, 'format': \"json\"}      \n",
    "        r = requests.get(URL, params=payload)\n",
    "        patterns = r.json().get('bustime-response').get('ptr')\n",
    "        \n",
    "        if not patterns:\n",
    "            print \"A very bad error has occurred\"\n",
    "              \n",
    "        for pattern in patterns:\n",
    "            pid = str(pattern['pid'])\n",
    "            rt = str(df[df.pid == pid].rt.unique()[0])\n",
    "            with open(os.path.join(patterns_path, \"{}_{}.json\".format(rt, pid)), 'w') as out_file:\n",
    "                json.dump(pattern, out_file)\n",
    "                \n",
    "def untangle_pattern_columns(df, pid):\n",
    "    stops_df = pd.DataFrame(df.loc['pt', pid])\n",
    "    pattern_info_df = pd.DataFrame(df.loc[~df.index.isin(['pt']), pid]).T.reset_index(drop=True)\n",
    "    pattern_df = stops_df.join(pattern_info_df)\n",
    "    ff_cols = ['first', 'last', 'ln', 'pid', 'rtdir']\n",
    "    pattern_df[ff_cols] = pattern_df[ff_cols].ffill()\n",
    "    pattern_df.pid = pattern_df.pid.astype(str)\n",
    "    return pattern_df\n",
    "\n",
    "def pattern_dict_to_df(json_dict):\n",
    "    df = pd.DataFrame(json_dict)\n",
    "    new_df = pd.concat([untangle_pattern_columns(df, pid) for pid in df.columns]).reset_index(drop=True)\n",
    "    new_df.drop(new_df[new_df.typ == \"W\"].index, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "def load_patterns(rt):\n",
    "    pattern_dict = {}\n",
    "    \n",
    "    for file in glob.glob(os.path.join(patterns_path, \"{}_*\".format(rt, pid))):\n",
    "        with open(file) as f:    \n",
    "            pattern = json.load(f)\n",
    "            \n",
    "        stops = [stop for stop in pattern['pt'] if stop['typ'] != \"W\"]\n",
    "        pattern['first'] = stops[0]['stpnm']\n",
    "        pattern['last'] = stops[-1]['stpnm']\n",
    "        pattern_dict[pattern['pid']] = pattern\n",
    "    \n",
    "    return pattern_dict_to_df(pattern_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the raw data <a name=\"cleaning\"></a>\n",
    "\n",
    "`remove_unknown_patterns`  \n",
    "Removes trips with pIDs for which there is no pattern data.\n",
    "\n",
    "`create_unique_id`  \n",
    "Tripids alone are not necessarily unique identifiers of a trip on a given route. This function creates a unique identifier for each trip by combining the start date of the trip, the pID of pattern it is executing, and its CTA-assigned tripid.\n",
    "\n",
    "Note: For the purposes of the CTA's scheduling, the new service day starts around 3AM. For example, if trip initially departs at 2AM on 2017-01-02, then the trip was scheduled for the 2017-01-01 service day. **Similarly, in this project 3AM US/Central time is treated as the start of a new day.**\n",
    "\n",
    "`remove_short_trips`  \n",
    "Removes data where bus travels less than 5,000 ft.\n",
    "\n",
    "`clean`  \n",
    "Removes duplicate rows and executes the above three functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_unknown_patterns(df, patterns):    \n",
    "    not_include = (set(df.pid) - set(patterns.pid))\n",
    "    df.drop(df[df.pid.isin(not_include)].index, inplace=True)\n",
    "    print \"Deleted pattern IDs {}\".format(list(not_include))\n",
    "\n",
    "def create_unique_ids(df):\n",
    "    df[\"unix_tmstmp\"] = df.tmstmp.apply(lambda x: arrow.get(x, 'US/Central').timestamp)\n",
    "    df.sort_values(['tripid', 'tmstmp'], inplace=True)\n",
    "    # If two data points with same tripID are more than 30 minutes a part, they probably belong to different trips\n",
    "    # In practice, such data points will usually (but not always), be at least 24 hours apart.\n",
    "    g = df.groupby(['tripid', (df.tmstmp.diff() > pd.Timedelta('30 minutes')).astype(int).cumsum()])\n",
    "    idxmins = g.unix_tmstmp.idxmin()\n",
    "    df_idxmins = df.loc[idxmins]\n",
    "    df.loc[idxmins, \"ID\"] = (df_idxmins.tmstmp - pd.DateOffset(hours=3)).dt.strftime('%Y%m%d') + \"_\" + df_idxmins.pid + \"_\" + df_idxmins.tripid\n",
    "    df.ID.ffill(inplace=True)\n",
    "\n",
    "def remove_short_trips(df):\n",
    "    df.drop(df.groupby('ID').filter(lambda x: x.pdist.max() - x.pdist.min() < 5000).index, inplace=True)\n",
    "            \n",
    "def clean(df, patterns):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    remove_unknown_patterns(df, patterns)\n",
    "    create_unique_ids(df)\n",
    "    remove_short_trips(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building timetables <a name=\"timetable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`build_query_strings`  \n",
    "Builds string to query DataFrame of raw data to determine the raw data point immediately before the buses arrived at the given stop and the raw data point immediately after the bus departed from that stop.\n",
    "\n",
    "`find_linear_interpolant_endpoints`  \n",
    "Finds the raw data points immediately before the buses arrived at the given stop and the raw data point immediately after the bus departed from that stop.\n",
    "\n",
    "`build_interpolation_table`  \n",
    "Organizes raw vehicle position data into tabular form to speed up interpolation calculation. Each row corresponds to a unique bus trip, and the columns correspond to values to be substitued into the formula for linear interpolation.\n",
    "\n",
    "`interpolate_stop_arrival_times`  \n",
    "Given a DataFrame of raw vehicle position data, a DataFrame of the bus route's patterns, and a bus stop, performs [linear interpolation](https://en.wikipedia.org/wiki/Linear_interpolation) to determine the time at which the observed buses arrived at the given bus stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_query_strings(stop, patterns):\n",
    "    filtered = patterns[patterns.stpnm == stop][[\"pid\", \"pdist\"]]\n",
    "    #stop_pdist = shift_terminal_stop_pdist(patterns, pattern, stop)\n",
    "\n",
    "    query_str_before = \" | \".join([\"(pid == '{}' & pdist < {})\".format(pid, pdist) for pid, pdist in zip(filtered.pid, filtered.pdist)])\n",
    "    query_str_after = \" | \".join([\"(pid == '{}' & pdist >= {})\".format(pid, pdist) for pid, pdist in zip(filtered.pid, filtered.pdist)])\n",
    "    return query_str_before, query_str_after\n",
    "\n",
    "def find_linear_interpolant_endpoints(df, stop, patterns):\n",
    "    query_str_before, query_str_after = build_query_strings(stop, patterns)\n",
    "\n",
    "    idxmaxs = df.query(query_str_before).groupby('ID').unix_tmstmp.idxmax()\n",
    "    idxmins = df.query(query_str_after).groupby('ID').unix_tmstmp.idxmin()\n",
    "\n",
    "    before = df.loc[idxmaxs, [\"pdist\", \"unix_tmstmp\", \"ID\"]].set_index(\"ID\")\n",
    "    after = df.loc[idxmins, [\"pdist\", \"unix_tmstmp\", \"ID\"]].set_index(\"ID\")\n",
    "\n",
    "    return before, after\n",
    "\n",
    "def build_interpolation_table(df, stop, patterns):\n",
    "    table = pd.DataFrame(np.nan, index=df.ID.unique(), columns=[stop])\n",
    "    table = table.join(df.groupby('ID').pid.first())\n",
    "\n",
    "    before, after = find_linear_interpolant_endpoints(df, stop, patterns)\n",
    "    table = table.join(before, rsuffix=\"_before\").join(after, rsuffix=\"_after\")\n",
    "\n",
    "    pid_to_pdist = patterns[patterns.stpnm == stop].groupby('pid').pdist.first()\n",
    "    mask = table.pid.isin(pid_to_pdist.index)\n",
    "    table.loc[mask, \"stop_pdist\"] = table[mask].pid.map(pid_to_pdist)\n",
    "\n",
    "    return table\n",
    "\n",
    "def interpolate_stop_arrival_times(table, stop):\n",
    "    table = build_interpolation_table(df, stop, patterns)\n",
    "    interpolated_arrivals = (\n",
    "            ((tableaux.unix_tmstmp_after - tableaux.unix_tmstmp) / (tableaux.pdist_after - tableaux.pdist))\n",
    "            * (tableaux.stop_pdist - tableaux.pdist)\n",
    "            + tableaux.unix_tmstmp\n",
    "        ) \n",
    "    mask = pd.notnull(interpolated_arrivals)\n",
    "    interpolated_arrivals.loc[mask] = interpolated_arrivals[mask].map(lambda x: arrow.get(x).to('US/Central').format('YYYY-MM-DD HH:mm:ss'))\n",
    "    return interpolated_arrivals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`build_bidirectional_timetable`  \n",
    "Builds a timetable DataFrame of interpolated arrival/departure times for each bus stop in either service direction on given route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Holiday schedules\n",
    "# Our services operate on a Sunday schedule on New Year’s Day, Memorial Day,\n",
    "# July 4th (Independence Day), Labor Day, Thanksgiving Day and Christmas Day.\n",
    "holidays = [\n",
    "    \"2017-01-01\", \"2017-05-29\", \"2017-07-04\", \"2018-09-04\", \"2018-11-23\", \"2017-12-25\",\n",
    "    \"2018-01-01\", \"2018-05-28\", \"2018-07-04\", \"2018-09-03\", \"2018-11-22\", \"2018-12-25\",\n",
    "    \"2019-01-01\", \"2019-05-27\", \"2019-07-04\", \"2019-09-02\", \"2019-11-28\", \"2019-12-25\"\n",
    "]\n",
    "cta_holidays = pd.DatetimeIndex(holidays)\n",
    "timetables_path = \"../../data/processed/timetables/\"\n",
    "\n",
    "def build_bidirectional_timetable(df, patterns):\n",
    "    stop_list = patterns.stpnm.dropna().unique()\n",
    "    timetable = pd.DataFrame(np.nan, index=df.ID.unique(), columns=stop_list)\n",
    "    timetable.index.name = \"ID\"\n",
    "\n",
    "    for stop in stop_list:\n",
    "        timetable[stop] = interpolate_stop_arrival_times(df, stop, patterns)\n",
    "    \n",
    "    timetable.reset_index(inplace=True)\n",
    "    timetable[[\"start_date\", \"pid\", \"tatripid\"]] = timetable.ID.str.split(\"_\", expand=True)\n",
    "    timetable[\"rtdir\"] = timetable.pid.map(patterns.groupby('pid').rtdir.first())\n",
    "    timetable[\"start_date\"] = pd.to_datetime(timetable.start_date)\n",
    "    timetable[\"day_of_week\"] = timetable.start_date.dt.dayofweek\n",
    "    timetable[\"holiday\"] = timetable.start_date.isin(cta_holidays)\n",
    "    return timetable\n",
    "\n",
    "def write_timetables(df):\n",
    "    timetable = interpolate_arrival_times(df)\n",
    "    check_if_path_exists(timetables_path)\n",
    "    #split timetable into two pieces based on patterns\n",
    "    #.to_csv(timetables_path + str(rt) + \"_timetable_\" + (direction[0].lower() + \"b\") + \".csv\", index=False)\n",
    "    \n",
    "def load_timetable(filename):\n",
    "    timetable = pd.read_csv(timetables_path + filename)\n",
    "    timetable[stop_list] = timetable[stop_list].apply(pd.to_datetime)\n",
    "    return timetable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shift_terminal_stop_pdists`  \n",
    "There is a significant amount of noise at the terminal stops of a route. This function shifts the location of the terminal stops inward by 500 feet. For example, if the first stop is located has a pdist of 0ft and the final stop has a pdist of 50,000ft, then `interpolate_arrival_times` treats these stops as being located at 500ft and 49,500ft, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_terminal_stop_pdists(patterns):\n",
    "    patterns.loc[np.intersect1d(patterns.groupby('pid').seq.idxmin(), patterns[patterns.pdist < 500].index), \"pdist\"] = 500\n",
    "\n",
    "    idxs = np.intersect1d(patterns.groupby('pid').seq.idxmax(), patterns[patterns.pdist > patterns.ln - 500].index)\n",
    "    pattern_lengths = patterns.loc[idxs].ln \n",
    "    patterns.loc[idxs, \"pdist\"] = pattern_lengths - 500\n",
    "    \n",
    "def process_raw_data(path, stem, rt):\n",
    "    df = load_raw_data(path, stem)\n",
    "    df.drop(df[df.rt != rt].index, inplace=True)\n",
    "    patterns = load_patterns(rt)\n",
    "    shift_terminal_stop_pdists(patterns)\n",
    "    clean(df, patterns)\n",
    "    build_timetable(df, patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived Data<a name=\"#derived\"></a>\n",
    "### Trip and Wait Times<a name=\"#trips_waits\"></a>\n",
    "\n",
    "`get_destination_stops`  \n",
    "Returns a list of the possible destination stops for a bus route, given the route's patterns DataFrame, the starting stop, and the travel direction.\n",
    "\n",
    "`timedelta_to_decimal`  \n",
    "Converts a a pandas `TimeDelta` to its duration in minutes rounded to two decimal places.\n",
    "\n",
    "`calculate_travel_times`  \n",
    "Calculates the travel times between an origin and destination stop given a timetable DataFrame.\n",
    "\n",
    "`calculate_wait_times`  \n",
    "Calculates the wait times between consecutive buses given a timetable DataFrame. If consecutive buses have different service days, sets the calculated wait time to `None`.\n",
    "\n",
    "`build_travel_waits_df`  \n",
    "Given a bus route's timetable DataFrame, pattern DataFrame, and travel direction, calculates the travel times between each bus stop on the route and the wait times between adjacent buses at each stop. Stores the calculations in a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_destination_stops(patterns, stop, direction):\n",
    "    filtered = patterns[(patterns.stpnm == stop) & (patterns.rtdir == direction)]\n",
    "    query_str = \" | \".join([\"(pid == '{}' & seq > {})\".format(pid, seq) for pid, seq in zip(filtered.pid, filtered.seq)])\n",
    "    return list(patterns.query(query_str).stpnm.unique())\n",
    "\n",
    "def timedelta_to_decimal(td):\n",
    "    return round(abs((td / np.timedelta64(1, 'D')) * 1440), 2)\n",
    "\n",
    "def calculate_travel_times(df, origin, destinations):\n",
    "    df[destinations] = df[destinations].sub(df[origin], axis=0)\n",
    "    df[destinations] = df[destinations].apply(timedelta_to_decimal)\n",
    "    return df\n",
    "\n",
    "def calculate_wait_times(df, stop):\n",
    "    df[\"wait_time\"] = df[stop] - df[stop].shift(-1)\n",
    "        \n",
    "    # removes wait times calculated between service days\n",
    "    df[\"day_diff\"] = df.start_date - df.start_date.shift(-1)\n",
    "    df.loc[df.day_diff.dt.days != 0, \"wait_time\"] = None\n",
    "    \n",
    "    df.drop(columns=[stop, \"day_diff\"], inplace=True)\n",
    "    df.wait_time = df.wait_time.apply(timedelta_to_decimal)\n",
    "    return df\n",
    "\n",
    "def build_travel_waits_df(df, patterns, direction):\n",
    "    info_columns = [\"start_date\", \"pid\", \"tatripid\", \"rtdir\", \"day_of_week\", \"holiday\", \"decimal_time\", \"wait_time\"]\n",
    "    \n",
    "    stop_list = patterns[patterns.rtdir == direction].stpnm.dropna().unique()\n",
    "    directional_df = df.loc[df.rtdir == direction]\n",
    "    directional_df[stop_list] = directional_df[stop_list].apply(pd.to_datetime)\n",
    "    \n",
    "    travels_waits = []\n",
    "    for origin in stop_list:\n",
    "        destinations = get_destination_stops(patterns, origin, direction)\n",
    "        \n",
    "        if not destinations:\n",
    "            continue\n",
    "\n",
    "        orgin_and_dests = [origin] + destinations\n",
    "        sorted_df = directional_df.sort_values(by=origin) # sorting by arrival times in origin column\n",
    "        sorted_df[\"decimal_time\"] = sorted_df[origin].map(lambda x: round(x.hour + x.minute / 60.0, 2))\n",
    "\n",
    "        sorted_df = calculate_travel_times(sorted_df, origin, destinations)        \n",
    "        sorted_df = calculate_wait_times(sorted_df, origin)\n",
    "\n",
    "        melted_df = pd.melt(sorted_df, id_vars=info_columns, value_vars=destinations, var_name=\"destination\", value_name=\"travel_time\")\n",
    "        melted_df.dropna(subset=[\"wait_time\", \"travel_time\"], inplace=True)\n",
    "        melted_df[\"origin\"] = origin\n",
    "        travels_waits.append(melted_df)\n",
    "    return pd.concat(travels_waits, ignore_index=True)\n",
    "\n",
    "def write_travel_waits():\n",
    "    #travel_waits_path = \"../../data/processed/trips_and_waits/\" + str(rt) + \"/\"\n",
    "    #check_if_path_exists(travel_waits_path)\n",
    "    #file_name = travel_waits_path + origin.replace(\"/\", \"\").replace(\".\", \"\") + \"_\" + direction + \".csv\"\n",
    "    #melted_df.to_csv(file_name, columns=header, header=False, index=False, mode='ab+')\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
